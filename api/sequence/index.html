
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../assets/boun_logo.png">
      <meta name="generator" content="mkdocs-1.4.1, mkdocs-material-8.5.6">
    
    
      
        <title>sequence - pydebiaseddta</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.20d9efc8.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#sequence" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="pydebiaseddta" class="md-header__button md-logo" aria-label="pydebiaseddta" data-md-component="logo">
      
  <img src="../../assets/boun_logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            pydebiaseddta
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              sequence
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9v1Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/rizaozcelik/pydebiaseddta/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="pydebiaseddta" class="md-nav__button md-logo" aria-label="pydebiaseddta" data-md-component="logo">
      
  <img src="../../assets/boun_logo.png" alt="logo">

    </a>
    pydebiaseddta
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/rizaozcelik/pydebiaseddta/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Homepage
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../debiasing/" class="md-nav__link">
        debiasing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../predictors/" class="md-nav__link">
        predictors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../guides/" class="md-nav__link">
        guides
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation/" class="md-nav__link">
        evaluation
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          sequence
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        sequence
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence" class="md-nav__link">
    pydebiaseddta.sequence
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.smiles_processing" class="md-nav__link">
    pydebiaseddta.sequence.smiles_processing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.smiles_processing.segment_smiles" class="md-nav__link">
    segment_smiles()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.smiles_processing.segment_smiles_batch" class="md-nav__link">
    segment_smiles_batch()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification" class="md-nav__link">
    pydebiaseddta.sequence.word_identification
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier" class="md-nav__link">
    WordIdentifier
  </a>
  
    <nav class="md-nav" aria-label="WordIdentifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.encode_sequences" class="md-nav__link">
    encode_sequences()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.from_file" class="md-nav__link">
    from_file()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.tokenize_sequences" class="md-nav__link">
    tokenize_sequences()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.train" class="md-nav__link">
    train()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.load_chemical_word_identifier" class="md-nav__link">
    load_chemical_word_identifier()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.load_protein_word_identifier" class="md-nav__link">
    load_protein_word_identifier()
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence" class="md-nav__link">
    pydebiaseddta.sequence
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.smiles_processing" class="md-nav__link">
    pydebiaseddta.sequence.smiles_processing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.smiles_processing.segment_smiles" class="md-nav__link">
    segment_smiles()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.smiles_processing.segment_smiles_batch" class="md-nav__link">
    segment_smiles_batch()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification" class="md-nav__link">
    pydebiaseddta.sequence.word_identification
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier" class="md-nav__link">
    WordIdentifier
  </a>
  
    <nav class="md-nav" aria-label="WordIdentifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.encode_sequences" class="md-nav__link">
    encode_sequences()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.from_file" class="md-nav__link">
    from_file()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.save" class="md-nav__link">
    save()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.tokenize_sequences" class="md-nav__link">
    tokenize_sequences()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.WordIdentifier.train" class="md-nav__link">
    train()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.load_chemical_word_identifier" class="md-nav__link">
    load_chemical_word_identifier()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydebiaseddta.sequence.word_identification.load_protein_word_identifier" class="md-nav__link">
    load_protein_word_identifier()
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/rizaozcelik/pydebiaseddta/edit/master/docs/api/sequence.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="sequence">sequence</h1>


<div class="doc doc-object doc-module">


<a id="pydebiaseddta.sequence"></a>
  <div class="doc doc-contents first">
  
      <p>The submodule for processing SMILES strings. 
<code>smiles_processing.py</code> consists of utility function to segment SMILES strings, 
whereas <code>word_identification.py</code> consists of a class to learn biomolecule words and segment biomolecule sequences into biomolecule words.</p>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-module">


<a id="pydebiaseddta.sequence.smiles_processing"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h2 id="pydebiaseddta.sequence.smiles_processing.segment_smiles" class="doc doc-heading">
<code class="highlight language-python"><span class="n">segment_smiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">,</span> <span class="n">segment_sq_brackets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Segments a SMILES string into its tokens.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>smiles</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>Input SMILES string.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>segment_sq_brackets</code></td>
          <td>
                <code>bool, optional</code>
          </td>
          <td><p>Whether to segment expressions within square brackets (<em>e.g.</em> [C@@H], [Rb]), too. 
Set to <code>True</code> to have square brackets and the tokens inside as standalone tokens,
<em>e.g.</em> ["[", "C", "@", "@", "H", "]"]. 
When set to <code>False</code>, whole expression is returned as a single token, <em>e.g.</em> "[C@@H]" .
Defaults to <code>True</code>.</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>Each element of the SMILES string as a list.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\smiles_processing.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">segment_smiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">segment_sq_brackets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Segments a SMILES string into its tokens.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    smiles : str</span>
<span class="sd">        Input SMILES string.</span>
<span class="sd">    segment_sq_brackets : bool, optional</span>
<span class="sd">        Whether to segment expressions within square brackets (*e.g.* [C@@H], [Rb]), too. </span>
<span class="sd">        Set to `True` to have square brackets and the tokens inside as standalone tokens,</span>
<span class="sd">        *e.g.* [&quot;[&quot;, &quot;C&quot;, &quot;@&quot;, &quot;@&quot;, &quot;H&quot;, &quot;]&quot;]. </span>
<span class="sd">        When set to `False`, whole expression is returned as a single token, *e.g.* &quot;[C@@H]&quot; .</span>
<span class="sd">        Defaults to `True`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[str]</span>
<span class="sd">        Each element of the SMILES string as a list.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">regex</span> <span class="o">=</span> <span class="n">_RE_PATTERNS</span><span class="p">[</span><span class="s2">&quot;segmentation_sq&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">segment_sq_brackets</span><span class="p">:</span>
        <span class="n">regex</span> <span class="o">=</span> <span class="n">_RE_PATTERNS</span><span class="p">[</span><span class="s2">&quot;segmentation&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">regex</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="pydebiaseddta.sequence.smiles_processing.segment_smiles_batch" class="doc doc-heading">
<code class="highlight language-python"><span class="n">segment_smiles_batch</span><span class="p">(</span><span class="n">smiles_batch</span><span class="p">,</span> <span class="n">segment_sq_brackets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Segments multiple SMILES strings with a single call by wrapping <code>sequence.smiles_processing.segment_smiles</code>.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>smiles_batch</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>List of input SMILES strings.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>segment_sq_brackets</code></td>
          <td>
                <code>bool, optional</code>
          </td>
          <td><p>Whether to segment expressions within square brackets. 
See <code>sequence.smiles_processing.segment_smiles</code> for a more detailed explanation.
Defaults to <code>True</code>.</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.List">List</span>[<span title="typing.List">List</span>[str]]</code>
          </td>
          <td><p>A 2D list of strings where element <span class="arithmatex">\([i][j]\)</span> corresponds to the <span class="arithmatex">\(j^{th}\)</span> token of the <span class="arithmatex">\(i^{th}\)</span> input.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\smiles_processing.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">segment_smiles_batch</span><span class="p">(</span>
    <span class="n">smiles_batch</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">segment_sq_brackets</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;Segments multiple SMILES strings with a single call by wrapping `sequence.smiles_processing.segment_smiles`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    smiles_batch : List[str]</span>
<span class="sd">        List of input SMILES strings.</span>
<span class="sd">    segment_sq_brackets : bool, optional</span>
<span class="sd">        Whether to segment expressions within square brackets. </span>
<span class="sd">        See `sequence.smiles_processing.segment_smiles` for a more detailed explanation.</span>
<span class="sd">        Defaults to `True`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[List[str]]</span>
<span class="sd">        A 2D list of strings where element $[i][j]$ corresponds to the $j^{th}$ token of the $i^{th}$ input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">segment_smiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">,</span> <span class="n">segment_sq_brackets</span><span class="p">)</span> <span class="k">for</span> <span class="n">smiles</span> <span class="ow">in</span> <span class="n">smiles_batch</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">


<a id="pydebiaseddta.sequence.word_identification"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="pydebiaseddta.sequence.word_identification.WordIdentifier" class="doc doc-heading">
        <code>WordIdentifier</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>A versatile class to identify biomolecule words in biomolecule strings. 
<code>WordIdentifier</code> leverages the Byte Pair Encoding algorithm implemented in the <code>tokenizers</code> library
to learn biomolecule vocabularies and segment biomolecule strings into their words.</p>


        <details class="quote">
          <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">WordIdentifier</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A versatile class to identify biomolecule words in biomolecule strings. </span>
<span class="sd">    `WordIdentifier` leverages the Byte Pair Encoding algorithm implemented in the `tokenizers` library</span>
<span class="sd">    to learn biomolecule vocabularies and segment biomolecule strings into their words. </span>
<span class="sd">    &quot;&quot;&quot;</span>    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a `WordIdentifier` instance.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        vocab_size : int</span>
<span class="sd">            Size of the biomolecule vocabulary.</span>
<span class="sd">        &quot;&quot;&quot;</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">BPE</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pre_tokenizer</span> <span class="o">=</span> <span class="n">Whitespace</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">loadpath</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Loads a `WordIdentifier` from a file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loadpath : str</span>
<span class="sd">            Path to the `WordIdentifier` file.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        WordIdentifier</span>
<span class="sd">            Previously saved `WordIdentifier`</span>
<span class="sd">        &quot;&quot;&quot;</span>        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">loadpath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">FILE_EXTENSION</span><span class="p">):</span>
            <span class="n">loadpath</span> <span class="o">=</span> <span class="n">loadpath</span> <span class="o">+</span> <span class="n">FILE_EXTENSION</span>

        <span class="n">dct</span> <span class="o">=</span> <span class="n">load_json</span><span class="p">(</span><span class="n">loadpath</span><span class="p">)</span>
        <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dct</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">][</span><span class="s2">&quot;vocab&quot;</span><span class="p">])</span>
        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
        <span class="n">instance</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="o">.</span><span class="n">from_str</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">dct</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">instance</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">corpus_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Learns a biomolecule vocabulary from a file of biomolecule strings using Byte Pair Encoding Algorithm. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        corpus_path : str</span>
<span class="sd">            Path to the corpus of biomolecule strings. The corpus file must contain a biomolecule string per line.</span>
<span class="sd">        &quot;&quot;&quot;</span>        
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">BpeTrainer</span><span class="p">(</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">train</span><span class="p">([</span><span class="n">corpus_path</span><span class="p">],</span> <span class="n">trainer</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab_size</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Warning: The iterations stopped before the desired vocab size is reached. Learned vocab size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab_size</span><span class="p">()</span><span class="si">}</span><span class="s2">. Desired size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">tokenize_sequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Segments a List of biomolecule strings into biomolecule words via the learned vocabulary.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sequences : List[str]</span>
<span class="sd">            The List of biomolecule strings.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        List[List[str]]</span>
<span class="sd">            List of biomolecule words of each input string.</span>
<span class="sd">        &quot;&quot;&quot;</span>        
        <span class="n">encodings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_batch</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">encoding</span><span class="o">.</span><span class="n">tokens</span> <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">encodings</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">encode_sequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">padding_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Segments a List of biomolecule strings into biomolecule words via the learned vocabulary and </span>
<span class="sd">        returns the id of the biomolecule word, which is convenient to apply label encoding in the subsequent steps.</span>
<span class="sd">        Padding support is also available to ease training deep learning possible.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sequences : List[str]</span>
<span class="sd">            The List of biomolecule strings.</span>
<span class="sd">        padding_len : int, optional</span>
<span class="sd">            The desired length of sequences, by default `None`. No padding is applied when set to `None`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        List[List[int]]</span>
<span class="sd">            List of the id of the biomolecule words of each input string.</span>
<span class="sd">        &quot;&quot;&quot;</span>        
        <span class="n">encodings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_batch</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding_len</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">encodings</span><span class="p">:</span>
                <span class="n">encoding</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                    <span class="n">padding_len</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="n">pad_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;[PAD]&quot;</span>
                <span class="p">)</span>
                <span class="n">encoding</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">padding_len</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">encoding</span><span class="o">.</span><span class="n">ids</span> <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">encodings</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">savepath</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Saves a `WordIdentifier` instance to disk.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        savepath : str</span>
<span class="sd">            The path to dump the instance. File extension is added automatically.</span>
<span class="sd">        &quot;&quot;&quot;</span>        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">savepath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">FILE_EXTENSION</span><span class="p">):</span>
            <span class="n">savepath</span> <span class="o">=</span> <span class="n">savepath</span> <span class="o">+</span> <span class="n">FILE_EXTENSION</span>
        <span class="n">save_json</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">to_str</span><span class="p">()),</span> <span class="n">savepath</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="pydebiaseddta.sequence.word_identification.WordIdentifier.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Creates a <code>WordIdentifier</code> instance.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>vocab_size</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Size of the biomolecule vocabulary.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `WordIdentifier` instance.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vocab_size : int</span>
<span class="sd">        Size of the biomolecule vocabulary.</span>
<span class="sd">    &quot;&quot;&quot;</span>        
    <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">BPE</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pre_tokenizer</span> <span class="o">=</span> <span class="n">Whitespace</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="pydebiaseddta.sequence.word_identification.WordIdentifier.encode_sequences" class="doc doc-heading">
<code class="highlight language-python"><span class="n">encode_sequences</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">padding_len</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Segments a List of biomolecule strings into biomolecule words via the learned vocabulary and 
returns the id of the biomolecule word, which is convenient to apply label encoding in the subsequent steps.
Padding support is also available to ease training deep learning possible.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>sequences</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>The List of biomolecule strings.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>padding_len</code></td>
          <td>
                <code>int, optional</code>
          </td>
          <td><p>The desired length of sequences, by default <code>None</code>. No padding is applied when set to <code>None</code>.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.List">List</span>[<span title="typing.List">List</span>[int]]</code>
          </td>
          <td><p>List of the id of the biomolecule words of each input string.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">encode_sequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">padding_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;Segments a List of biomolecule strings into biomolecule words via the learned vocabulary and </span>
<span class="sd">    returns the id of the biomolecule word, which is convenient to apply label encoding in the subsequent steps.</span>
<span class="sd">    Padding support is also available to ease training deep learning possible.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sequences : List[str]</span>
<span class="sd">        The List of biomolecule strings.</span>
<span class="sd">    padding_len : int, optional</span>
<span class="sd">        The desired length of sequences, by default `None`. No padding is applied when set to `None`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[List[int]]</span>
<span class="sd">        List of the id of the biomolecule words of each input string.</span>
<span class="sd">    &quot;&quot;&quot;</span>        
    <span class="n">encodings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_batch</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding_len</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">encodings</span><span class="p">:</span>
            <span class="n">encoding</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                <span class="n">padding_len</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="n">pad_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;[PAD]&quot;</span>
            <span class="p">)</span>
            <span class="n">encoding</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">padding_len</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">encoding</span><span class="o">.</span><span class="n">ids</span> <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">encodings</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="pydebiaseddta.sequence.word_identification.WordIdentifier.from_file" class="doc doc-heading">
<code class="highlight language-python"><span class="n">from_file</span><span class="p">(</span><span class="n">loadpath</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

</h3>


  <div class="doc doc-contents ">
  
      <p>Loads a <code>WordIdentifier</code> from a file.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>loadpath</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>Path to the <code>WordIdentifier</code> file.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-internal" title="pydebiaseddta.sequence.word_identification.WordIdentifier" href="#pydebiaseddta.sequence.word_identification.WordIdentifier">WordIdentifier</a></code>
          </td>
          <td><p>Previously saved <code>WordIdentifier</code></p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">loadpath</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Loads a `WordIdentifier` from a file.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    loadpath : str</span>
<span class="sd">        Path to the `WordIdentifier` file.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    WordIdentifier</span>
<span class="sd">        Previously saved `WordIdentifier`</span>
<span class="sd">    &quot;&quot;&quot;</span>        
    <span class="k">if</span> <span class="ow">not</span> <span class="n">loadpath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">FILE_EXTENSION</span><span class="p">):</span>
        <span class="n">loadpath</span> <span class="o">=</span> <span class="n">loadpath</span> <span class="o">+</span> <span class="n">FILE_EXTENSION</span>

    <span class="n">dct</span> <span class="o">=</span> <span class="n">load_json</span><span class="p">(</span><span class="n">loadpath</span><span class="p">)</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dct</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">][</span><span class="s2">&quot;vocab&quot;</span><span class="p">])</span>
    <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">instance</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="o">.</span><span class="n">from_str</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">dct</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">instance</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="pydebiaseddta.sequence.word_identification.WordIdentifier.save" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">savepath</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Saves a <code>WordIdentifier</code> instance to disk.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>savepath</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>The path to dump the instance. File extension is added automatically.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">savepath</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Saves a `WordIdentifier` instance to disk.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    savepath : str</span>
<span class="sd">        The path to dump the instance. File extension is added automatically.</span>
<span class="sd">    &quot;&quot;&quot;</span>        
    <span class="k">if</span> <span class="ow">not</span> <span class="n">savepath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">FILE_EXTENSION</span><span class="p">):</span>
        <span class="n">savepath</span> <span class="o">=</span> <span class="n">savepath</span> <span class="o">+</span> <span class="n">FILE_EXTENSION</span>
    <span class="n">save_json</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">to_str</span><span class="p">()),</span> <span class="n">savepath</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="pydebiaseddta.sequence.word_identification.WordIdentifier.tokenize_sequences" class="doc doc-heading">
<code class="highlight language-python"><span class="n">tokenize_sequences</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Segments a List of biomolecule strings into biomolecule words via the learned vocabulary.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>sequences</code></td>
          <td>
                <code><span title="typing.List">List</span>[str]</code>
          </td>
          <td><p>The List of biomolecule strings.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.List">List</span>[<span title="typing.List">List</span>[str]]</code>
          </td>
          <td><p>List of biomolecule words of each input string.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">tokenize_sequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;Segments a List of biomolecule strings into biomolecule words via the learned vocabulary.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sequences : List[str]</span>
<span class="sd">        The List of biomolecule strings.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[List[str]]</span>
<span class="sd">        List of biomolecule words of each input string.</span>
<span class="sd">    &quot;&quot;&quot;</span>        
    <span class="n">encodings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_batch</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">encoding</span><span class="o">.</span><span class="n">tokens</span> <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">encodings</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="pydebiaseddta.sequence.word_identification.WordIdentifier.train" class="doc doc-heading">
<code class="highlight language-python"><span class="n">train</span><span class="p">(</span><span class="n">corpus_path</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Learns a biomolecule vocabulary from a file of biomolecule strings using Byte Pair Encoding Algorithm. </p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>corpus_path</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>Path to the corpus of biomolecule strings. The corpus file must contain a biomolecule string per line.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">corpus_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Learns a biomolecule vocabulary from a file of biomolecule strings using Byte Pair Encoding Algorithm. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    corpus_path : str</span>
<span class="sd">        Path to the corpus of biomolecule strings. The corpus file must contain a biomolecule string per line.</span>
<span class="sd">    &quot;&quot;&quot;</span>        
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">BpeTrainer</span><span class="p">(</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">train</span><span class="p">([</span><span class="n">corpus_path</span><span class="p">],</span> <span class="n">trainer</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab_size</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Warning: The iterations stopped before the desired vocab size is reached. Learned vocab size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab_size</span><span class="p">()</span><span class="si">}</span><span class="s2">. Desired size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="pydebiaseddta.sequence.word_identification.load_chemical_word_identifier" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load_chemical_word_identifier</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>A convenience function to load word vocabularies learned for SMILES strings in the study.
The possible vocabularies to load are for DeepDTA and BPE-DTA. </p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>vocab_size</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Size of the learned SMILES word vocabulary. The allowed values are 94 and 8000, for DeepDTA and BPE-DTA, respectively.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>type[<a class="autorefs autorefs-internal" title="pydebiaseddta.sequence.word_identification.WordIdentifier" href="#pydebiaseddta.sequence.word_identification.WordIdentifier">WordIdentifier</a>]</code>
          </td>
          <td><p>The <code>WordIdentifier</code> instance used by the DTA models.</p></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>If vocabulary size besides 94 and 8000 is passed, a <code>ValueError</code> is raised.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load_chemical_word_identifier</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WordIdentifier</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A convenience function to load word vocabularies learned for SMILES strings in the study.</span>
<span class="sd">    The possible vocabularies to load are for DeepDTA and BPE-DTA. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vocab_size : int</span>
<span class="sd">        Size of the learned SMILES word vocabulary. The allowed values are 94 and 8000, for DeepDTA and BPE-DTA, respectively.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    type[WordIdentifier]</span>
<span class="sd">        The `WordIdentifier` instance used by the DTA models.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If vocabulary size besides 94 and 8000 is passed, a `ValueError` is raised.</span>
<span class="sd">    &quot;&quot;&quot;</span>    
    <span class="k">if</span> <span class="n">vocab_size</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">94</span><span class="p">,</span> <span class="mi">8000</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Supported vocab sizes are 94 and 8000&quot;</span><span class="p">)</span>

    <span class="n">protein_vocab_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">package_path</span><span class="si">}</span><span class="s2">/data/word_identification/chemical&quot;</span>
    <span class="n">vocab_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">protein_vocab_path</span><span class="si">}</span><span class="s2">/chembl27_enc_94.json&quot;</span>
    <span class="k">if</span> <span class="n">vocab_size</span> <span class="o">==</span> <span class="mi">8000</span><span class="p">:</span>
        <span class="n">vocab_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">protein_vocab_path</span><span class="si">}</span><span class="s2">/chembl27_enc_bpe_8000.json&quot;</span>

    <span class="k">return</span> <span class="n">WordIdentifier</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="pydebiaseddta.sequence.word_identification.load_protein_word_identifier" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load_protein_word_identifier</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>A convenience function to load word vocabularies learned for amino-acid sequences in the study.
The possible vocabularies to load are for DeepDTA and BPE-DTA. </p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>vocab_size</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Size of the learned SMILES word vocabulary. The allowed values are 26 and 32000, for DeepDTA and BPE-DTA, respectively.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>type[<a class="autorefs autorefs-internal" title="pydebiaseddta.sequence.word_identification.WordIdentifier" href="#pydebiaseddta.sequence.word_identification.WordIdentifier">WordIdentifier</a>]</code>
          </td>
          <td><p>The <code>WordIdentifier</code> instance used by the DTA models.</p></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>If vocabulary size besides 26 and 32000 is passed, a <code>ValueError</code> is raised.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>pydebiaseddta\sequence\word_identification.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load_protein_word_identifier</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">WordIdentifier</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A convenience function to load word vocabularies learned for amino-acid sequences in the study.</span>
<span class="sd">    The possible vocabularies to load are for DeepDTA and BPE-DTA. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vocab_size : int</span>
<span class="sd">        Size of the learned SMILES word vocabulary. The allowed values are 26 and 32000, for DeepDTA and BPE-DTA, respectively.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    type[WordIdentifier]</span>
<span class="sd">        The `WordIdentifier` instance used by the DTA models.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If vocabulary size besides 26 and 32000 is passed, a `ValueError` is raised.</span>
<span class="sd">    &quot;&quot;&quot;</span>    
    <span class="k">if</span> <span class="n">vocab_size</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">26</span><span class="p">,</span> <span class="mi">32000</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Supported vocab sizes are 26 and 32000&quot;</span><span class="p">)</span>

    <span class="n">protein_vocab_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">package_path</span><span class="si">}</span><span class="s2">/data/word_identification/protein&quot;</span>
    <span class="n">vocab_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">protein_vocab_path</span><span class="si">}</span><span class="s2">/uniprot_26.json&quot;</span>
    <span class="k">if</span> <span class="n">vocab_size</span> <span class="o">==</span> <span class="mi">32000</span><span class="p">:</span>
        <span class="n">vocab_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">protein_vocab_path</span><span class="si">}</span><span class="s2">/uniprot_bpe_32000.json&quot;</span>

    <span class="k">return</span> <span class="n">WordIdentifier</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../evaluation/" class="md-footer__link md-footer__link--prev" aria-label="Previous: evaluation" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              evaluation
            </div>
          </div>
        </a>
      
      
        
        <a href="../utils/" class="md-footer__link md-footer__link--next" aria-label="Next: utils" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              utils
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.078830c0.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>